{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate the Logistic Regression API. We will use text data to do a binary classification task.\n",
    "1. Create Count Matrix\n",
    "2. Build Logitic Regression Model\n",
    "3. Apply Regularization\n",
    "4. Do grid search to tune regularization terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir=\"E:\\Work\\Machine Learning Course\\Python\\Module 3 Logistic Regression\\Data\"\n",
    "# os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a tab-separated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data=pd.read_table('movie_reviews.tsv',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset about movie reviews. We have a label for each reviews. 1-reviewer thought the movie was good. 0-reviewer thought the movie was not that great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier to predict if a reviewer will like a movie(1) or not(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "sentiment    0\n",
       "review       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           object\n",
       "sentiment     int64\n",
       "review       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.00000\n",
       "mean         0.50000\n",
       "std          0.50001\n",
       "min          0.00000\n",
       "25%          0.00000\n",
       "50%          0.50000\n",
       "75%          1.00000\n",
       "max          1.00000\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data['sentiment'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "median shows 50%. So count of 1s and 0s are 50-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting text to a predictor matrix. We use a common technique - A Term-document matrix refers to the count of each word in each row of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating text features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='dtm.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is sentence one.',\n",
       " 'This is sentence two.',\n",
       " 'This is a very very long sentence three.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating Features\n",
    "demo_text=[\"This is sentence one.\", \"This is sentence two.\", \"This is a very very long sentence three.\"]\n",
    "demo_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a TD matrix for these 3 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a count vectorizer. Use fit_transform to convert the list into a matrix of count of each word in the sentences in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass input=['This is sentence one.', 'This is sentence two.', 'This is a very very long sentence three.'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['is', 'long', 'one', 'sentence', 'this', 'three', 'two', 'very']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=text.CountVectorizer(demo_text)\n",
    "count_matrix=cv.fit_transform(demo_text)\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 0, 1, 1, 1, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st rows represents the word count for 1st list - 1-'is',0-'long', 1-'one' and so on. there's no 'long' in the first sentence right? 'very' occurs twice in the last sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another way to represent count array is to convert into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>long</th>\n",
       "      <th>one</th>\n",
       "      <th>sentence</th>\n",
       "      <th>this</th>\n",
       "      <th>three</th>\n",
       "      <th>two</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is  long  one  sentence  this  three  two  very\n",
       "0   1     0    1         1     1      0    0     0\n",
       "1   1     0    0         1     1      0    1     0\n",
       "2   1     1    0         1     1      1    0     2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_matrix.toarray(),columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create TD matrix for the reviews column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember - always pass text data as a list. We will also put a threshold on the max columns that can be created in the data. With text data you have many unique words and creating a count data could end up with many columns - lots of computation when building the model. Sklearn gives the ability to put a threshold on the max number of columns in the count matrix. (to figure out a good number you will have to experiment with data to see at what number your system is able to build the model - here 5000 works well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create Features for the linear classifier \n",
    "cv=text.CountVectorizer(review_data['review'].tolist(),max_features = 5000)\n",
    "X=cv.fit_transform(review_data['review'])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=review_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "X_train,X_test,y_train,y_test=model_selection.train_test_split(X,y,test_size=0.2,random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as linear_model\n",
    "clf=linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "mod=clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.82074568e-01, 4.17925432e-01],\n",
       "       [9.99058031e-01, 9.41968521e-04],\n",
       "       [9.99997391e-01, 2.60857042e-06],\n",
       "       ...,\n",
       "       [1.93622997e-03, 9.98063770e-01],\n",
       "       [9.99797884e-01, 2.02116408e-04],\n",
       "       [9.99815212e-01, 1.84787872e-04]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get two probabilities corresponding to class 0 and 1. Which corresponds to what, take a look at .classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence is [0,1] so first column correponds to probabilities for class 0 and the second for class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"api.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization in sklearn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularized Cost Function, l2 norm = $-\\sum_{1}^{n} [y_i log(p_i)+(1-y_i)log(1-p_i)]+\\frac{1}{C}\\beta^2$, here $\\frac{1}{C}=\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularized Cost Function, l1 norm = $-\\sum_{1}^{n}[ y_i log(p_i)+(1-y_i)log(1-p_i)]+\\frac{1}{C}|\\beta|$, here $\\frac{1}{C}=\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression models can be regularized. If we look at the shape of predictor matrix - 25000 rows and 5000 columns. If we use all 5000 columns, there are chances we might overfit our model. So we need to introduce some sort of regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to figure out what would be the regularizing parameter, we do a GridSearch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is quite large, doing an extensive gridsearch will be computationally expensive so just for the demonstration, lets do a gridsearch for two random values for parameter 'C'. \n",
    "sklearn treats reg parameters differently - instead of lambda, scikit uses 1/c. 1/c in sklearn doc is = lambda that is higher values of c for lower values of lambda. and penalty-we give L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\VK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([54.13470824, 26.52268101]),\n",
       "                         'penalty': ['l2']})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(300)\n",
    "mod=model_selection.GridSearchCV(clf,param_grid={\"penalty\":[\"l2\"],\"C\":np.random.uniform(0,120,2)})\n",
    "mod.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=26.522681005625447)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best estimator is a logistic regression model with c=26.52 which means lambda would be 1/26.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8587"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## accuracy score\n",
    "mod.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.94863106e-01, 8.05136894e-01],\n",
       "       [9.99969747e-01, 3.02533962e-05],\n",
       "       [9.99999750e-01, 2.49602794e-07],\n",
       "       ...,\n",
       "       [1.48131157e-03, 9.98518688e-01],\n",
       "       [9.99637726e-01, 3.62273534e-04],\n",
       "       [9.99917982e-01, 8.20183814e-05]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roc curve - we pass actuals with predicted probs of class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , ..., 0.96233148, 0.96233148,\n",
       "        1.        ]),\n",
       " array([0.00000000e+00, 8.07102502e-04, 1.93704600e-02, ...,\n",
       "        9.99596449e-01, 1.00000000e+00, 1.00000000e+00]),\n",
       " array([2.00000000e+00, 1.00000000e+00, 9.99999998e-01, ...,\n",
       "        1.22771170e-08, 1.20289086e-08, 2.66152258e-25]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_curve(y_test,mod.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st array talks about fpr, second about tpr, third talks about the thresholds at which the above fprs and tprs are computed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store fpr, tpr and threshold into objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,thresholds=metrics.roc_curve(y_test,mod.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'true positive rate')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr,\"-\")\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks to be doing a good job than a naive classifier - the curve is at the top left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9360811301227167"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test,mod.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2172,  350],\n",
       "       [ 316, 2162]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,mod.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87      2522\n",
      "           1       0.86      0.87      0.87      2478\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,mod.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
